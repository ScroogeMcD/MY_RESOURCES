# System Design questions
## Contents
* [Design a URL shortening service](#design-a-url-shortening-service)
* [Design a unique Id generator](#design-a-unique-id-generator)
* [Design an API rate limiter](#design-an-api-rate-limiter)
* [Design typeahead suggestion](#design-typeahead-suggestion)
* [Design a web crawler](#design-a-web-crawler)
* [Design a chat service](#design-a-chat-service)

**Follow this order** : 
* **Functional Requirements** : analytics apart from other things
* **Non-functional requirements** : Availability, latency, etc
* **Read Heavy vs Write Heavy system**
* **Estimations**
* **Deep Dive on algorithm**
  - APIs  :
    - what data exchange format to use: external-> JSON, internal->gRPC and protobuf
  - design : 
    - Is a message queue required here ? 
    - SQL vs NoSQL etc
    - Bloom Filters, Streams, Stateless vs Stateful, minimizing network calls, LSM DBs etc., semaphores, locks etc
* **Data partition and replication** : consistent hashing, sharding etc
* **Analytics APIs** : using CDC probably
* Data purging
* Metrics and monitoring, rate limiting
* Security

## Design a URL shortening service
Key points : 
- system will be read-heavy
- APIs
  - ```String shortenURL(String longURL)```
  - ```String getLongURL(String shortURL)```
- a base64 encoding, with 6 characters in the shortened URL can support 64^6 =~ 68 billion URLs
- Idea 1 : 
  - Hash the long URL to generate the short URL
  - The hash would be around 128 bits, or 16 bytes, of which we need only 6 bytes, so multiple URLs can get same short URL, leading to collisions
- Idea 2 : 
  - Pre-generate all the possible 6 byte permutations of Base 64, and randomly assign them IDs. Store the IDs and corresponding ShortURL in DB
  - When a request for shortening a URL comes, assign it the next unassigned short URL, and add the long URL in the DB corresponding to this short URL
  - This prevents two Long URLs from getting the same short URL
  - To prevent same long URL from getting multiple short URLs, everytime a createShortURL API is invoked, check if the long URL already exists in the DB.
    Since this will be a costly operation, as our key is short URL and not long URL, we can maintain a **Bloom Filter** of already added long URLs.
    If bloom filter returns that a long URL is not added yet, it is 100% true, however if it says a long URL is present, we need to then check the DB, since
    bloom filters can return false positives.
- Cache (with LRU eviction) the short URLs
- Add analytics through CDC on the DB
- Sharding
  - based onn first letter of short URLs will lead to unbalances shards
  - use consistent hashing, to split the short URL set across multiple DB Servers based on their hash
- If required have keep-alive times for each entry, so that they can be purged after some time.


## Design a unique Id generator
- need IDs with 64 bits
- If the IDs need to be absolutely sortable, then it is difficult to get this right across multiple servers. This is because of clocks across machines not in sync.
- If we need almost-sortable ids, then it is slightly easier to work with. For ex. the precision can be 1 second. 
  However for two ids generated on different machines within 1 second, we might not realy be able to guarantee ordering.
- **Option 1** : k DB servers, each generating incremental id in the form base+k, where base is server id. So for 3 servers:
  - server 1 -> 1, 4, 7, 10, 13 ...
  - server 2 -> 2, 5, 8, 11, 14,...
  - server 3 -> 3, 6, 9, 12, 15

  - problem : difficult to add servers
- **Option 2 : UUIDs**
  - UUIDs are 128 bit long, but we want 64 bits
  - UUIDs are not sortable by time

- **Option 3 : Twitter snowflake like**
  - Of the 64 bits, say first 40 bits can be used to denote epoch since a specific time, say 1970 (or starting point of our service, basically our earliest timestamp)
  - next 8 bits can be used to denote machine id (256 machines)
  - remaining 16 bits can be used to have a sequence number(upto 65,536) within a machine. It is to be reset to zero every millisecond.


## Design an API rate limiter   
Rate limiting algorithms :
* **Fixed Window**
  - Map of <UserId:{Count,window_start_time_in_mins}>
    Ex : User1:{Count:3, window_start_time_in_mins: 10:55AM}
* **Sliding window**
  - Map of <UserId : SortedListOfLoginTimes>
    Ex : User1:{10:55:01, 10:55:45, 10:56:02}
    Whenever the next request appears, remove all the entries that are not within the window, and then add this one if there is still space.
* **Mix of both**

## Design typeahead suggestion

## Design a web crawler

## Design a chat service
