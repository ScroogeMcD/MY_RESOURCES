# System Design questions
## Contents
* [Design a URL shortening service](#design-a-url-shortening-service)
* [Design a unique Id generator](#design-a-unique-id-generator)
* [Design an API rate limiter](#design-an-api-rate-limiter)
* [Design typeahead suggestion](#design-typeahead-suggestion)
* [Design a web crawler](#design-a-web-crawler)
* [Design a chat service](#design-a-chat-service)

**Follow this order** : 
* Functional Requirements : analytics apart from other things
* Non-functional requirements : Availability, latency, etc
* Read Heavy vs Write Heavy system
* Estimations
* Deep Dive on algorithm
  - APIs
  - design
* Data partition and replication : consistent hashing, sharding etc
* Analytics APIs
* Data purging
* Metrics and monitoring, rate limiting
* Security

## Design a URL shortening service
Key points : 
- system will be read-heavy
- a base64 encoding, with 6 characters in the shortened URL can support 64^6 =~ 68 billion URLs
- Idea 1 : 
  - Hash the long URL to generate the short URL
  - The hash would be around 128 bits, or 16 bytes, of which we need only 6 bytes, so multiple URLs can get same short URL, leading to collisions
- Idea 2 : 
  - Pre-generate all the possible 6 byte permutations of Base 64, and randomly assign them IDs. Store the IDs and corresponding ShortURL in DB
  - When a request for shortening a URL comes, assign it the next unassigned short URL, and add the long URL in the DB corresponding to this short URL
- Cache (with LRU eviction) the short URLs
- Add analytics through CDC on the DB
- Sharding
  - based onn first letter of short URLs will lead to unbalances shards
  - use consistent hashing, to split the short URL set across multiple DB Servers based on their hash
- If required have keep-alive times for each entry, so that they can be purged after some time.


## Design a unique Id generator

## Design an API rate limiter

## Design typeahead suggestion

## Design a web crawler

## Design a chat service
