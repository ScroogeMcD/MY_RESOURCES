# Zookeeper

## 1. Zookeeper's Data Model
![Zookeeper_1](https://user-images.githubusercontent.com/13499858/122635094-8d40bc80-d0ff-11eb-80cd-80dfda244f6b.png)

ZNode's properties :
* Hybrid between a file and a directory
  * Znodes can store data inside (like a file)
  * Znodes can have children znodes (like a directory)
* Two types of Znodes :
  * Persistent - persists between sessions
  * Ephemeral - is deleted when the session ends

Some useful zookeeper commands [from within zookeeper installation's bin directory]:
* **zkServer.sh start** => starts server on the port specified in the default config file
* **zkCli.sh** => start a shell that connect to the zk server started above
* ls, create [path] [data], deleteall [path], get -s [path]
<details>
  
  <summary> Zookeeper CLI commands </summary>
  
  ![ZK_CLI](https://user-images.githubusercontent.com/13499858/122644337-5932bf00-d132-11eb-8744-aa892ec367c8.png)

</details>

## 2. Zookeeper's Client Threading Model and Java API
* Application's start code in the main method is executed on the main thread.
* When Zookeeper object is created, two additional threads are created :
  * **Event Thread** 
    * manages Zookeeper events
      * Connection (KeeperState.SyncConnected)
      * Disconnection (KeeperState.Disconnected)
    * Custom znode Watchers and Triggers we subscribe to
    * All events coming from Zookeeper are executed on this Event Thread in the order of arrival from Zokeeper
  * **IO Thread**
    * handles all the network communication with Zookeeper servers
    * handles Zookeeper requests and responses
    * responds to pings
    * session management
    * session timeouts etc

## 3. Leader Election and Watchers, Triggers
**Leader Election**
* all nodes connect to the zookeeper, under an application specific znode (say /leader_election) and get assigned a connection id (say /leader_election/candidate_1).
* The cluster node with the smallest node_id wins the election.
```java
   public void volunteerForLeadership() throws InterruptedException, KeeperException {
        String znodePrefix = ELECTION_NAMESPACE + "/candidate_";
        String znodeFullPath = zk.create(znodePrefix, new byte[]{}, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL);

        logger.info("znode full path : " + znodeFullPath);
        currentZnodeName = znodeFullPath.replace(ELECTION_NAMESPACE + "/", "");
    }

    public void electLeader() throws InterruptedException, KeeperException {
        List<String> children = zk.getChildren(ELECTION_NAMESPACE, false);
        Collections.sort(children);
        String smallestChild = children.get(0);

        if(smallestChild.equals(currentZnodeName))
            logger.info("I am the leader");
        else
            logger.info("I am not the leader. Leader is : " + smallestChild);
    }
```


* We can register a watcher when we call the methods :
  * ```getChildren(..., watcher)``` - get notified when the list of a znode's children changes
  * ```getData(znodePath, watcher)``` - get notified when a znode's data gets modified
  * ```exists(znodePath, watcher)``` - get notified when a znode gets deleted or created
* The watcher allows us to get a notification when a change happens.
* ```public Zookeeper(String connectString, int sessionsTImeout, Watcher watcher)``` - Also takes a watcher
* Watchers registered with getChildren(), exists() and getData() are **one-time triggers**
* If we want to get future notifications, we need to register the watcher again.
* During LeaderElection :
  * Each cluster node can start watching the leader znode;
  * As soon as the leader node dies, they all get notified simultaneously

**Leader Re-election and The Herd Effect**
* A large number of nodes waiting for an event.
* When the event happens, all nodes get notified and they all wake up.
* Only one node can "succeed"
* Indicates bad design, can negatively impact the performance and can completely freeze the cluster.
* **Re-election strategy 1** : On leader failure, all other nodes will simultaneously invoke getChildren(), and then once when the next leader is re-elected, all of them are again going to send the watchEvent calls. This will bombard the zookeeper server and should be avoided.
* **Re-election strategy 2** : Each node sets a watch only on its immediate previous znode. Thus only one node gets notified when the leader dies.

![Zookeeper_leader](https://user-images.githubusercontent.com/13499858/122671884-509bc080-d1e6-11eb-9227-caf45451b7ee.png)


