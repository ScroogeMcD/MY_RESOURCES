# KAFKA


## Kafka - installation locations on my Macbook
* the log dir (directory where the topic-partition log files are stored) is defined at ```/usr/local/etc/kafka/server.properties``` by the name ```log.dirs```
* The log dir mentioned by default in the above location is ``/usr/local/var/lib/kafka-logs```
* Under this logs directory, there are directories with the name format as ```<topicName>-<partitionNumber>```, for ex. stockPriceTopic-0
* Under this logs directory, there is a special topic called ```__consumer_offsets``` which mantains the last committed offset per consumerGroup and partition.
* executing tree command under one of the partition directories, prints the following as an example :</br>
```
   |___00000000000000000005.index</br>
   |___00000000000000000005.log</br>
   |___00000000000000000005.timeindex</br>
   |___00000000000000000011.snapshot</br>
   |___leader-epoch-checkpoint</br>
   |___partition.metadata</br>
```
* to dump the contents of one of the log or index files ```kafka-dump-log --files 00000000000000000005.log```

## Kafka Storage internals
### Segments
* partitions in kafka are further divided into smaller elements called **segments**
* Each group of files within the partition directory constitutes a **segment**. For ex. in the above listing 
   * ```00000000000000000005.index```, 
   * ```00000000000000000005.log``` and 
   * ```00000000000000000005.timeindex``` 
   form a group. There might be multiple such groups.
* The suffix at the end of the file name (in this example : 5) represents the minimum offset of the partition within this file. It means, this log files contains records with offset 5 and above.
* How does kafka know when to create a new segment ?
   * For this, kafka relies on the properties **log.segment.bytes** at a broker level, or **segment.bytes** at a topic level. Once a segment's size reaches this limit, a new segment gets created.

### .log file
* if we use kafka-dump-log on one of the log files, we get something similar to the following :
```
baseOffset: 57 lastOffset: 64 count: 8 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 3252 CreateTime: 1635662466006 size: 1270 magic: 2 compresscodec: none crc: 3063812793 isvalid: true
| offset: 57 CreateTime: 1635662465776 keySize: 55 valueSize: 86 sequence: -1 headerKeys: [] key: {"stockId":111,"stockName":"MSFT","date":1577989800000} payload: {"stockPriceKey":{"stockId":111,"stockName":"MSFT","date":1577989800000},"price":30.0}
| offset: 58 CreateTime: 1635662465781 keySize: 55 valueSize: 87 sequence: -1 headerKeys: [] key: {"stockId":112,"stockName":"GOOG","date":1577989800000} payload: {"stockPriceKey":{"stockId":112,"stockName":"GOOG","date":1577989800000},"price":31.01}
..........
|offset: 63 CreateTime: 1635662465993 keySize: 55 valueSize: 86 sequence: -1 headerKeys: [] key: {"stockId":211,"stockName":"MSFT","date":1577989800000} payload: {"stockPriceKey":{"stockId":211,"stockName":"MSFT","date":1577989800000},"price":30.0}
| offset: 64 CreateTime: 1635662466006 keySize: 55 valueSize: 87 sequence: -1 headerKeys: [] key: {"stockId":212,"stockName":"GOOG","date":1577989800000} payload: {"stockPriceKey":{"stockId":212,"stockName":"GOOG","date":1577989800000},"price":31.01}
```
baseOffset : offset of first message in the batch
lastOffset : offset of last message in the batch

### .index file
Since the consumers process messages continuously, extracting a message from a partition given an offset is a common operation.
Finding the specific offset within a partition is a two step process :
 * identifying which segment in the partition contains this offset
 * finding the exact location in the file, within the .log file of the segment

Identifying the segment can be done using a binary search on the name of the file.
Finding the exact location within the segment might require a complete file scan, unless we maintain some kind of index for the locations in the .log file. This is the purpose that the .index file serves.

It contains entries of the form :
offset:15 position:250
offset:30 position:640

So first index above would mean the record with </br>```offset = base_offset_from_the_file_name + relative_offset_from_the_index``` can be found within the .log file at the byte location 250.

### .timeindex file

## Kafka CLI
* To list down the kafka topics </br>
``kafka-topics --bootstrap-server localhost:9092 --list``
* To create a topic</br> 
``kafka-topics --bootstrap-server localhost:9092 --topic stockPriceTopic -- create --partitions 3 --replication-factor 1``</br>
  We cannot have a replication factor of more than 1, if we have only one available broker in our cluster
* To describe a topic </br>
``kafka-topics --bootstrap-server localhost:9092 --topic stockPriceTopic --describe``

## Producer 
To connect to the Kafka broker, we need to set come configurations in a ```java.util.Properties``` object :
```java
Properties props = new Properties();
props.put("bootstrap.servers",bootstrapServers);  // bootstrapServers is a string consisting of comma-separated localhost:port addresses of brokers
props.put("acks","all");
props.put("key.serializer","com.example.base.domain.StockPriceKeySerializer");
props.put("value.serializer","com.example.base.domain.StockPriceSerializer");
props.put("partitioner.class","com.example.base.stockproducer.StockBasedPartitioner");
kafkaProducer = new KafkaProducer<>(props);
```

API to write to a topic on this broker cluster:
```java
// (topicName,key,value) is required as params
ProducerRecord<StockPriceKey, StockPrice> record = new ProducerRecord<>(TOPIC_NAME_STOCK_PRICE, sp.getStockPriceKey(), sp); 
kafkaProducer.send(record, new Callback() {
  @Override
  public void onCompletion(RecordMetadata metadata, Exception exception) {
    System.out.print("Key : \t" + sp.getStockPriceKey());
    System.out.print("Topic : \t" + metadata.topic() + "\t");
    System.out.print("Partition : \t" + metadata.partition() + "\t");
    System.out.println("Offset : \t" + metadata.offset());
  }
});
```
In the ProducerRecord constructor,
* If a valid partition number is provided, then the record is appended to that partition.
* If no partition number is provided but a key is used, then the partition is chosen based on the hash of the key.
* If neither key nor partition is present, then the partition is assigned in a round-robin fashion.

Different constructors to create a producer record :
```java
// API 1
public ProducerRecord(String topic, Integer partition, Long timestamp, K key, V value, Iterable<Header> headers)

// API 2
public ProducerRecord(String topic, Integer partition, Long timestamp, K key, V value)

// API 3
public ProducerRecord(String topic, Integer partition, K key, V value, Iterable<Header> headers)

// API 4
public ProducerRecord(String topic, Integer partition, K key, V value)

// API 5
public ProducerRecord(String topic, K key, V value)

// API 6
public ProducerRecord(String topic, V value)
```


## Consumer
* **STEP 01 : Properties to create a kafkaConsumer object**
```java
private KafkaConsumer<StockPriceKey, StockPrice> kafkaConsumer;

Properties props = new Properties();
props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, Constants.bootstrapServers);
props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,"com.example.base.domain.StockPriceKeyDeserializer");
props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, "com.example.base.domain.StockPriceDeserializer");
props.put(ConsumerConfig.GROUP_ID_CONFIG, consumerGroupId);
props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, "4");
props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");

kafkaConsumer = new KafkaConsumer<>(props);
```
* **STEP 02 : subscribe to the topic**
```java
kafkaConsumer.subscribe(Arrays.asList(Constants.TOPIC_NAME_STOCK_PRICE));
```
* **STEP 03 : poll the broker**
```java
while(true){
  ConsumerRecords<StockPriceKey, StockPrice> records = kafkaConsumer.poll(Duration.ofMinutes(1));
  for(ConsumerRecord<StockPriceKey, StockPrice> record : records){
    System.out.println(record.key() + "\t" + record.value());
    System.out.println("Partition : " + record.partition() + ",\t offset: " + record.offset());
  }
}
```

There is no background thread in the java consumer. The API depends on calls to ```poll()``` to drive all of its I/O, including :
* joining the consumer group and handling parition rebalances
* sending periodic heartbeats if part of an active generation
* sending periodic offset commits (if autocommit is enabled)
* sending and receving fetch requests for assigned partitions

## Consumer Groups
A consumer group is a set of consumers which cooperate to consume data from some topics. The partitions of all the topics are divided among the consumers in the group. As new group members arrive, and old group members leave, the partitions are reassigned so that each member receives a proportional share of the partitions. This is known as rebalancing the group.

## Offset Management
The internal topic  ```_consumer_offsets``` is used to store committed offsets.
After the consumer receives its assignment from the coordinator, it must determine the initial position for each assigned partition. 
As a consumer in the group reads messages from the partitions assigned by the coordinator, it must commit offsets corresponding to the messages it has read. If the consumer crashes or is shut down, its partitions will be re-assigned to another member, which will begin consumption from the last committed offset of each partition.

The offset commit policy is crucial to providing the message delivery guarantees. By default, the consumer is configured to use an automatic commit policy, which triggers a commit on a periodic interval. Using 'auto-commit' gives us ```at-least-once``` delivery.

## Partition Rebalancing
* Within a ConsumerGroup, each partition of a topic is exclusively assigned to one consumer.
* If more consumers join the ConsumerGroup, and if there are more number of partitions than the number of consumers, then the partitions are rebalanced
so that some of the existing partitions are moved to new consumers, to distribute the load.
* If there are more number of consumers than the number of partitions, then some of the consumers would remain idle. 

## Kafka delivery guarantees
* **at-least-once** by default
* for **exactly once** - producer side, i.e. make the producer idempotent
   * with idempotency turned on, each kafka message gets two things : 
      * a **producer id (PID)** 
      * a **sequence number (seq)**
   * during message retries, the topic will accept only those messages which have a new unique sequence id and producer id.
   * ```producerProps.put("enable.idempotence",true)```
   * ```producerProps.put("transactional.id","100")```
* 

## Transactions

## Useful links
* https://docs.confluent.io/clients-kafka-java/current/overview.html
* https://www.confluent.io/blog/transactions-apache-kafka/
