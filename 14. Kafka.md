# KAFKA


## Kafka CLI
* To list down the kafka topics </br>
``kafka-topics --bootstrap-server localhost:9092 --list``
* To create a topic</br> 
``kafka-topics --bootstrap-server localhost:9092 --topic stockPriceTopic -- create --partitions 3 --replication-factor 1``</br>
  We cannot have a replication factor of more than 1, if we have only one available broker in our cluster
* To describe a topic </br>
``kafka-topics --bootstrap-server localhost:9092 --topic stockPriceTopic --describe``

## Producer 
To connect to the Kafka broker, we need to set come configurations in a ```java.util.Properties``` object :
```java
Properties props = new Properties();
props.put("bootstrap.servers",bootstrapServers);  // bootstrapServers is a string consisting of comma-separated localhost:port addresses of brokers
props.put("acks","all");
props.put("key.serializer","com.example.base.domain.StockPriceKeySerializer");
props.put("value.serializer","com.example.base.domain.StockPriceSerializer");
props.put("partitioner.class","com.example.base.stockproducer.StockBasedPartitioner");
kafkaProducer = new KafkaProducer<>(props);
```

API to write to a topic on this broker cluster:
```java
// (topicName,key,value) is required as params
ProducerRecord<StockPriceKey, StockPrice> record = new ProducerRecord<>(TOPIC_NAME_STOCK_PRICE, sp.getStockPriceKey(), sp); 
kafkaProducer.send(record, new Callback() {
  @Override
  public void onCompletion(RecordMetadata metadata, Exception exception) {
    System.out.print("Key : \t" + sp.getStockPriceKey());
    System.out.print("Topic : \t" + metadata.topic() + "\t");
    System.out.print("Partition : \t" + metadata.partition() + "\t");
    System.out.println("Offset : \t" + metadata.offset());
  }
});
```
In the ProducerRecord constructor,
* If a valid partition number is provided, then the record is appended to that partition.
* If no partition number is provided but a key is used, then the partition is chosen based on the hash of the key.
* If neither key nor partition is present, then the partition is assigned in a round-robin fashion.

Different constructors to create a producer record :
```java
// API 1
public ProducerRecord(String topic, Integer partition, Long timestamp, K key, V value, Iterable<Header> headers)

// API 2
public ProducerRecord(String topic, Integer partition, Long timestamp, K key, V value)

// API 3
public ProducerRecord(String topic, Integer partition, K key, V value, Iterable<Header> headers)

// API 4
public ProducerRecord(String topic, Integer partition, K key, V value)

// API 5
public ProducerRecord(String topic, K key, V value)

// API 6
public ProducerRecord(String topic, V value)
```


## Consumer
* **STEP 01 : Properties to create a kafkaConsumer object**
```java
private KafkaConsumer<StockPriceKey, StockPrice> kafkaConsumer;

Properties props = new Properties();
props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, Constants.bootstrapServers);
props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,"com.example.base.domain.StockPriceKeyDeserializer");
props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, "com.example.base.domain.StockPriceDeserializer");
props.put(ConsumerConfig.GROUP_ID_CONFIG, consumerGroupId);
props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, "4");
props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");

kafkaConsumer = new KafkaConsumer<>(props);
```
* **STEP 02 : subscribe to the topic**
```java
kafkaConsumer.subscribe(Arrays.asList(Constants.TOPIC_NAME_STOCK_PRICE));
```
* **STEP 03 : poll the broker**
```java
while(true){
  ConsumerRecords<StockPriceKey, StockPrice> records = kafkaConsumer.poll(Duration.ofMinutes(1));
  for(ConsumerRecord<StockPriceKey, StockPrice> record : records){
    System.out.println(record.key() + "\t" + record.value());
    System.out.println("Partition : " + record.partition() + ",\t offset: " + record.offset());
  }
}
```

**Q. If a consumer restarts, how does it know which offset in the partition to resume from?**


## Partition Rebalancing
* Within a ConsumerGroup, each partition of a topic is exclusively assigned to one consumer.
* If more consumers join the ConsumerGroup, and if there are more number of partitions than the number of consumers, then the partitions are rebalanced
so that some of the existing partitions are moved to new consumers, to distribute the load.
* If there are more number of consumers than the number of partitions, then some of the consumers would remain idle. 

## Kafka delivery guarantees

## Transactions
